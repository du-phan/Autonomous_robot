{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "import time\n",
    "import datetime \n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import collections\n",
    "import unicodedata\n",
    "import collections\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from datetime import datetime, date, timedelta\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = 10,8\n",
    "\n",
    "plt.style.use('bmh')\n",
    "colors = ['#348ABD', '#A60628', '#7A68A6', '#467821', '#D55E00', \n",
    "          '#CC79A7', '#56B4E9', '#009E73', '#F0E442', '#0072B2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reward_table = [\n",
    "    [ -250 , -15000, -405 , -15000],\n",
    "    [-309 , -15000, -400 , 405  ],\n",
    "    [-262 , -15000, -255 , 400  ],\n",
    "    [-231 , -15000, -77  , 255  ],\n",
    "    [-61  , -15000, 0    , 77   ],\n",
    "    [0    , -15000, 0    , 0    ],\n",
    "    [0    , -15000, -15000, 0    ],\n",
    "    [-325 , 250  , -452 , -15000],\n",
    "    [-270 , 309  , -325 , 452  ],\n",
    "    [-200 , 262  , -190 , 325  ],\n",
    "    [-125 , 231  , -10  , 190  ],\n",
    "    [-2   , 61   , 0    , 10   ],\n",
    "    [0    , 0    , 0    , 0    ],\n",
    "    [0    , 0    , -15000, 0    ],\n",
    "    [-192 , 325  , -390 , -15000],\n",
    "    [-169 , 270  , -285 , -390 ],\n",
    "    [-105 , 200  , -132 , 285  ],\n",
    "    [-10  , 125  , -5   , 132  ],\n",
    "    [0    , 2    , 0    , 5    ],\n",
    "    [0    , 0    , 0    , 0    ],\n",
    "    [0    , 0    , -15000, 0    ],\n",
    "    [-117 , 192  , -350 , -15000],\n",
    "    [-67  , 169  , -235 , 350  ],\n",
    "    [-8   , 105  , -26  , 235  ],\n",
    "    [0    , 10   , 0    , 26   ],\n",
    "    [0    , 0    , 0    , 0    ],\n",
    "    [0    , 0    , 0    , 0    ],\n",
    "    [0    , 0    , -15000, 0    ],\n",
    "    [-38  , 117  , -250 , -15000],\n",
    "    [0    , 67   , -148 , 250  ],\n",
    "    [0    , 8    , -3   , 148  ],\n",
    "    [0    , 0    , 0    , 3    ],\n",
    "    [0    , 0    , 0    , 0    ],\n",
    "    [0    , 0    , 0    , 0    ],\n",
    "    [0    , 0    , -15000, 0    ],\n",
    "    [0    , 38   , -195 , -15000],\n",
    "    [0    , 0    , -193 , 195  ],\n",
    "    [0    , 0    , -5   , 193  ],\n",
    "    [0    , 0    , 0    , 5    ],\n",
    "    [0    , 0    , 0    , 0    ],\n",
    "    [0    , 0    , 0    , 0    ],\n",
    "    [0    , 0    , -15000, 0    ],\n",
    "    [-15000, 0    , -255 , -15000],\n",
    "    [-15000, 0    , -190 , 255  ],\n",
    "    [-15000, 0    , -8   , 190  ],\n",
    "    [-15000, 0    , 0    , 8   ],\n",
    "    [-15000, 0    , 0    , 0    ],\n",
    "    [-15000, 0    , 0    , 0    ],\n",
    "    [-15000, 0    , -15000, 0    ]\n",
    "]; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def softmax(f):\n",
    "    f = f - np.max(f)\n",
    "    p = np.exp(f) / np.sum(np.exp(f))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "softmax_reward_table = np.apply_along_axis(softmax, 1, reward_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def action_is_allowed(learner, state, action):\n",
    "\n",
    "    if (action == 0 and not(state > learner.num_states - learner.servo_num_states - 1)):\n",
    "        return True\n",
    "    elif (action == 1 and not(state < learner.servo_num_states)):\n",
    "        return True\n",
    "    elif (action == 2 and not((state%learner.servo_num_states) == (learner.servo_num_states-1))):\n",
    "        return True\n",
    "    elif (action == 3 and not(state%learner.servo_num_states==0)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class QLearner(object):\n",
    "    def __init__(self, \n",
    "                 servo_num_states, \n",
    "                 num_actions, \n",
    "                 alpha, \n",
    "                 gamma, \n",
    "                 random_action_rate,\n",
    "                 random_action_decay_rate, \n",
    "                 warm_up_period, \n",
    "                 action_penalty,\n",
    "                 negative_reward_coef,\n",
    "                 interest_zone_reward_coef,\n",
    "                 initial_state,\n",
    "                 scaling_point, \n",
    "                 scaling_factor):\n",
    "        \n",
    "        self.servo_num_states = servo_num_states\n",
    "        self.num_states = servo_num_states**2\n",
    "        self.num_actions = num_actions\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.random_action_rate = random_action_rate\n",
    "        self.random_action_decay_rate = random_action_decay_rate\n",
    "        self.warm_up_period = warm_up_period\n",
    "        self.state = initial_state\n",
    "        self.action = 0\n",
    "        self.action_penalty = action_penalty\n",
    "#         self.qtable = np.random.uniform(low=-1, high=1, size=(self.num_states, self.num_actions))\n",
    "#         self.qtable = np.zeros((self.num_states, self.num_actions))\n",
    "        self.qtable = np.ones((self.num_states, self.num_actions)) * 0\n",
    "        self.num_iteration = 0\n",
    "        self.last_reward = 0\n",
    "        self.negative_reward_coef = negative_reward_coef\n",
    "        self.interest_zone_reward_coef = interest_zone_reward_coef\n",
    "        self.scaling_point = scaling_point\n",
    "        self.scaling_factor = scaling_factor\n",
    "        \n",
    "    def set_initial_state(self, action):\n",
    "        \"\"\"\n",
    "        @summary: Sets the initial state and returns an action\n",
    "        @param state: The initial state\n",
    "        @returns: The selected action\n",
    "        \"\"\"\n",
    "        self.state = int(self.num_states/2)\n",
    "        self.action = action #self.qtable[state].argsort()[-1]\n",
    "        \n",
    "    def get_next_state(self):\n",
    "        \n",
    "        next_state = None\n",
    "        \n",
    "        if (self.action == 0 and action_is_allowed(self, self.state, self.action)): \n",
    "            next_state = self.state + self.servo_num_states\n",
    "        elif (self.action == 1 and action_is_allowed(self, self.state, self.action)):\n",
    "            next_state = self.state - self.servo_num_states\n",
    "        elif (self.action == 2 and action_is_allowed(self, self.state, self.action)):\n",
    "            next_state = self.state + 1\n",
    "        elif (self.action == 3 and action_is_allowed(self, self.state, self.action)):\n",
    "            next_state = self.state - 1 \n",
    "        else:\n",
    "            next_state = self.state;\n",
    "            \n",
    "        return next_state\n",
    "        \n",
    "    def move(self, state_prime, reward):\n",
    "        \"\"\"\n",
    "        @summary: Moves to the given state with given reward and returns action\n",
    "        @param state_prime: The new state\n",
    "        @param reward: The reward\n",
    "        @returns: The selected action\n",
    "        \"\"\"\n",
    "        alpha = self.alpha\n",
    "        gamma = self.gamma\n",
    "        state = self.state\n",
    "        action = self.action\n",
    "        qtable = self.qtable\n",
    "        action_prime = -1\n",
    "        \n",
    "#         if self.state == state_prime: \n",
    "\n",
    "#             while not self.action_is_allowed(action_prime):\n",
    "#                 action_prime = np.random.randint(0, self.num_actions)\n",
    "            \n",
    "#             self.action = action_prime\n",
    "            \n",
    "        if False:\n",
    "            print 'yo'\n",
    "            \n",
    "        else: \n",
    "            \n",
    "            choose_random_action = (1 - self.random_action_rate) <= np.random.uniform(0, 1)\n",
    "\n",
    "            if choose_random_action:\n",
    "#                 while not(action_is_allowed(self, state_prime, action_prime)): \n",
    "                action_prime = np.random.randint(0, self.num_actions)\n",
    "            else:\n",
    "                ordered_action_list = self.qtable[state_prime].argsort()\n",
    "                best_choice_index = -1\n",
    "#                 while not(action_is_allowed(self, state_prime, action_prime)):\n",
    "                action_prime = ordered_action_list[best_choice_index]\n",
    "#                     best_choice_index -= 1\n",
    "\n",
    "            if self.num_iteration > self.warm_up_period: # warm up period is over\n",
    "                self.random_action_rate *= self.random_action_decay_rate\n",
    "                    \n",
    "            \n",
    "#             if reward < 0 and np.abs(reward) < 15000:\n",
    "#                 reward = reward * self.negative_reward_coef\n",
    "            \n",
    "#             if self.num_iteration % 50 == 0:\n",
    "#                 qtable *= self.scaling_factor\n",
    "                \n",
    "            \n",
    "            qtable[state, action] = qtable[state, action] + alpha * (reward + gamma * qtable[state_prime, action_prime] - qtable[state, action])\n",
    "\n",
    "            self.state = state_prime\n",
    "            self.action = action_prime    \n",
    "            self.qtable = qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_final_reward(learner, reward_table, training_iteration):\n",
    "    \n",
    "    reward_list = []\n",
    "    \n",
    "    learned_reward_table = np.zeros((learner.num_states, learner.num_actions))\n",
    "    \n",
    "    num_exploration_step = 1000\n",
    "    \n",
    "    verbose = True\n",
    "    \n",
    "    for iteration_step in xrange(training_iteration):\n",
    "\n",
    "#         reward = reward_table[learner.state][learner.action] - learner.action_penalty\n",
    "\n",
    "#         if learner.state % learner.servo_num_states > 2 and learner.state < 30:\n",
    "#             reward = reward * learner.interest_zone_reward_coef if reward > 0 else reward\n",
    "            \n",
    "        if iteration_step < num_exploration_step: \n",
    "            \n",
    "            ideal_reward = reward_table[learner.state][learner.action] \n",
    "            random_noise = np.random.normal(0, np.abs(ideal_reward)*.25) if ideal_reward != 0 else 0 \n",
    "            noisy_reward = ideal_reward + random_noise - learner.action_penalty\n",
    "\n",
    "            if learner.state % learner.servo_num_states > 2 and learner.state < 30:\n",
    "                reward = noisy_reward * learner.interest_zone_reward_coef if noisy_reward > 0 else noisy_reward * learner.negative_reward_coef\n",
    "            else:\n",
    "                reward = noisy_reward\n",
    "\n",
    "            if learned_reward_table[learner.state][learner.action] != 0:\n",
    "                learned_reward_table[learner.state][learner.action] = .5*(learned_reward_table[learner.state][learner.action] + reward)\n",
    "            else:\n",
    "                learned_reward_table[learner.state][learner.action] = noisy_reward\n",
    "\n",
    "\n",
    "            next_state = learner.get_next_state()\n",
    "\n",
    "            learner.move(next_state, learned_reward_table[learner.state][learner.action])\n",
    "\n",
    "            learner.num_iteration += 1 \n",
    "\n",
    "            if learner.num_iteration % learner.scaling_point == 0: learner.qtable *= learner.scaling_factor\n",
    "\n",
    "            reward_list.append(learned_reward_table[learner.state][learner.action])\n",
    "        \n",
    "        else:\n",
    "            \n",
    "#             if verbose:\n",
    "#                 print \"Begin simulation\"\n",
    "                \n",
    "#             verbose = False\n",
    "            \n",
    "            reward = learned_reward_table[learner.state][learner.action]\n",
    "            reward_list.append(learned_reward_table[learner.state][learner.action])\n",
    "\n",
    "\n",
    "            next_state = learner.get_next_state()\n",
    "            learner.move(next_state, learned_reward_table[learner.state][learner.action])\n",
    "            learner.num_iteration += 1 \n",
    "\n",
    "            if learner.num_iteration % learner.scaling_point == 0: \n",
    "                learner.qtable *= learner.scaling_factor\n",
    "        \n",
    "    return np.mean(reward_list)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, hp, STATUS_OK, Trials\n",
    "import datetime\n",
    "\n",
    "best_score = np.inf\n",
    "\n",
    "def score(params):\n",
    "    \n",
    "    global best_score    \n",
    "    \n",
    "    num_iteration = 2\n",
    "    \n",
    "    loss_vector = []\n",
    "    \n",
    "    for i in xrange(num_iteration):\n",
    "    \n",
    "        learner = QLearner(servo_num_states = 7,\n",
    "                           num_actions=4,\n",
    "                           alpha=float(params['alpha']),\n",
    "                           gamma=float(params['gamma']),\n",
    "                           random_action_rate=float(params['random_action_rate']),\n",
    "                           random_action_decay_rate=float(params['random_action_decay_rate']),\n",
    "                           warm_up_period=int(params['warm_up_period']),\n",
    "                           action_penalty=50,\n",
    "                           negative_reward_coef=1, #float(params['negative_reward_coef']),\n",
    "                           interest_zone_reward_coef = 1, #float(params['interest_zone_reward_coef']),\n",
    "                           initial_state=10,\n",
    "                           scaling_point = int(params['scaling_point']),\n",
    "                           scaling_factor = float(params['scaling_factor']))#int(params['initial_state'])) #float(params['action_penalty']))\n",
    "        #learner.set_initial_state(action=0)\n",
    "\n",
    "        temp_loss = - get_final_reward(learner, reward_table, training_iteration=50000) # negative because we want to minimize loss\n",
    "        loss_vector.append(temp_loss)\n",
    "        \n",
    "    loss = np.mean(loss_vector)\n",
    "    \n",
    "    if loss < best_score: \n",
    "        print \"Searching...\", \n",
    "        print \"New best score: {0:.6f}\".format(-loss), \n",
    "        print params \n",
    "        print datetime.datetime.now().time()\n",
    "        print\n",
    "        best_score = loss\n",
    "\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "    \n",
    "def optimize(trials):\n",
    "        \n",
    "    space = {\n",
    "             'alpha': hp.uniform('alpha', 0.1, 1),\n",
    "             'gamma': hp.uniform('gamma', 0.1, 1),\n",
    "             'random_action_rate': hp.uniform('random_action_rate', 0.8,1), \n",
    "             'random_action_decay_rate': hp.uniform('random_action_decay_rate', 0.1, 1),\n",
    "             'warm_up_period': hp.quniform('warm_up_period', 50, 300, 10),\n",
    "             'scaling_point': hp.choice('scaling_point', np.arange(5,300, 5)),\n",
    "             'scaling_factor': hp.uniform('scaling_factor', 1., 5.)\n",
    "#              'initial_state': hp.quniform('initial_state', 0, 47, 1)\n",
    "#              'negative_reward_coef': hp.uniform('negative_reward_coef', 1, 1.5),\n",
    "#              'interest_zone_reward_coef': hp.uniform('interest_zone_reward_coef', 1, 1.5)\n",
    "            }\n",
    "\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=400)\n",
    "\n",
    "    print '------------------------' \n",
    "    print \"Done.\"\n",
    "    print \"Best parameter setting:\", best\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching... New best score: -35.352493 {'warm_up_period': 260.0, 'random_action_decay_rate': 0.142426083737119, 'scaling_factor': 1.3220198858172334, 'alpha': 0.5504661437202416, 'scaling_point': 170, 'gamma': 0.9457926799722469, 'random_action_rate': 0.8809362474632062}\n",
      "16:43:42.255444\n",
      "\n",
      "Searching... New best score: -9.286013 {'warm_up_period': 210.0, 'random_action_decay_rate': 0.632120451193053, 'scaling_factor': 1.0814874299050259, 'alpha': 0.5576989281907332, 'scaling_point': 100, 'gamma': 0.2505316293729903, 'random_action_rate': 0.8679148899000352}\n",
      "16:43:52.237360\n",
      "\n",
      "Searching... New best score: -7.930535 {'warm_up_period': 190.0, 'random_action_decay_rate': 0.5892996273746175, 'scaling_factor': 2.472819039005773, 'alpha': 0.7138669068673575, 'scaling_point': 255, 'gamma': 0.6701417050510539, 'random_action_rate': 0.842782858471514}\n",
      "16:44:43.994269\n",
      "\n",
      "Searching... New best score: 7.297269 {'warm_up_period': 60.0, 'random_action_decay_rate': 0.1835397681253017, 'scaling_factor': 2.979865536581502, 'alpha': 0.5851947066928254, 'scaling_point': 5, 'gamma': 0.4091624061994062, 'random_action_rate': 0.8936676490321234}\n",
      "16:45:19.106313\n",
      "\n",
      "Searching... New best score: 22.268678 {'warm_up_period': 100.0, 'random_action_decay_rate': 0.7710372836930308, 'scaling_factor': 3.1426155023340514, 'alpha': 0.5085043463618016, 'scaling_point': 145, 'gamma': 0.39419916878234634, 'random_action_rate': 0.8576662931979959}\n",
      "16:49:57.091124\n",
      "\n",
      "Searching... New best score: 37.673468 {'warm_up_period': 90.0, 'random_action_decay_rate': 0.824709435216204, 'scaling_factor': 3.6044006257743333, 'alpha': 0.3092353715331193, 'scaling_point': 275, 'gamma': 0.37419656297319936, 'random_action_rate': 0.834614308862227}\n",
      "16:50:33.988117\n",
      "\n",
      "------------------------\n",
      "Done.\n",
      "Best parameter setting: {'warm_up_period': 90.0, 'scaling_factor': 3.6044006257743333, 'random_action_decay_rate': 0.824709435216204, 'random_action_rate': 0.834614308862227, 'alpha': 0.3092353715331193, 'scaling_point': 54, 'gamma': 0.37419656297319936}\n",
      "CPU times: user 8min 43s, sys: 1.65 s, total: 8min 44s\n",
      "Wall time: 8min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Trials object where the history of search will be stored\n",
    "trials = Trials()\n",
    "\n",
    "best_params = optimize(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_state_temp(learner, state, action):\n",
    "    \n",
    "    next_state = None\n",
    "\n",
    "    if (action == 0 and action_is_allowed(learner, state, action)): \n",
    "        next_state = state + learner.servo_num_states\n",
    "    elif (action == 1 and action_is_allowed(learner, state, action)):\n",
    "        next_state = state - learner.servo_num_states\n",
    "    elif (action == 2 and action_is_allowed(learner, state, action)):\n",
    "        next_state = state + 1\n",
    "    elif (action == 3 and action_is_allowed(learner, state, action)):\n",
    "        next_state = state - 1 \n",
    "    else:\n",
    "        next_state = state;\n",
    "\n",
    "    return next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reward_bins = pd.cut([-800, 800], bins=500, retbins=True)[1][1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_bin(value, bins):\n",
    "        return np.digitize(x=[value], bins=bins)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/Users/admin/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:55: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "100%|██████████| 2/2 [00:00<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "26\n",
      "27\n",
      "26\n",
      "27\n",
      "26\n",
      "27\n",
      "26\n",
      "27\n",
      "26\n",
      "27\n",
      "26\n",
      "27\n",
      "26\n",
      "27\n",
      "26\n",
      "27\n",
      "26\n",
      "27\n",
      "26\n",
      "27\n",
      "26\n",
      "27\n",
      "26\n",
      "27\n",
      "26\n",
      "27\n",
      "26\n",
      "27\n",
      "\n",
      "Reward per action:  46.60825\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAHsCAYAAAAEiX1wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a98e110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def crawling_simulation(params, reward_table, training_iteration = 2000, num_simulation = 2):\n",
    "    \n",
    "    state_vector = np.zeros(49)\n",
    "    action_vector = np.zeros(4)\n",
    "    reward_vector = []\n",
    "    reward_bins = pd.cut([-800, 800], bins=200, retbins=True)[1][1:-1]\n",
    "\n",
    "    for simulation in tqdm(xrange(num_simulation)):\n",
    "        \n",
    "        temp_reward = []\n",
    "\n",
    "        learner = QLearner(servo_num_states = 7,\n",
    "                   num_actions=4,\n",
    "                   alpha=float(params['alpha']),\n",
    "                   gamma=float(params['gamma']),\n",
    "                   random_action_rate=float(params['random_action_rate']),\n",
    "                   random_action_decay_rate=float(params['random_action_decay_rate']),\n",
    "                   warm_up_period=int(params['warm_up_period']),\n",
    "                   action_penalty=50,\n",
    "                   negative_reward_coef=1.,#float(params['negative_reward_coef']),\n",
    "                   interest_zone_reward_coef = 1, #1.32, #float(params['interest_zone_reward_coef']),\n",
    "                   initial_state=24,\n",
    "                   scaling_point = params['scaling_point'],\n",
    "                   scaling_factor = params['scaling_factor'])#int(params['initial_state'])) #float(params['action_penalty']))\n",
    "\n",
    "        learned_reward_table = np.zeros((learner.num_states, learner.num_actions))\n",
    "    \n",
    "        for iteration_step in xrange(training_iteration):\n",
    "            \n",
    "            state_vector[learner.state] += 1\n",
    "            action_vector[learner.action] += 1 \n",
    "    \n",
    "            if iteration_step > training_iteration-30 and simulation == num_simulation-1:\n",
    "                print learner.state \n",
    "#                 print reward_table[1]\n",
    "#                 print learned_reward_table[1]\n",
    "               \n",
    "    \n",
    "#             if iteration_step % 500 == 0:\n",
    "#                 print np.mean(np.abs(learned_reward_table - reward_table))\n",
    "            \n",
    "            \n",
    "    \n",
    "            ideal_reward = reward_table[learner.state][learner.action] \n",
    "            random_noise = np.random.normal(0, np.abs(ideal_reward)*.25) if ideal_reward != 0 else 0 \n",
    "            noisy_reward = ideal_reward + random_noise - learner.action_penalty\n",
    "            \n",
    "            \n",
    "            if learner.state % learner.servo_num_states > 2 and learner.state < 30:\n",
    "                noisy_reward = noisy_reward * learner.interest_zone_reward_coef if noisy_reward > 0 else noisy_reward * learner.negative_reward_coef\n",
    "                  \n",
    "    \n",
    "#             noisy_reward = to_bin(noisy_reward, reward_bins)\n",
    "            \n",
    "            temp_bin_value = .5*(reward_bins[learned_reward_table[learner.state][learner.action]] + noisy_reward)\n",
    "\n",
    "            learned_reward_table[learner.state][learner.action] = to_bin(temp_bin_value, reward_bins)\n",
    "#             print noisy_reward\n",
    "            \n",
    "#             if learned_reward_table[learner.state][learner.action] != 0:\n",
    "#                 learned_reward_table[learner.state][learner.action] = .5*(learned_reward_table[learner.state][learner.action] + noisy_reward)\n",
    "#             else:\n",
    "#                 learned_reward_table[learner.state][learner.action] = noisy_reward\n",
    "                \n",
    "            \n",
    "            \n",
    "            temp_reward.append(learned_reward_table[learner.state][learner.action])\n",
    "            \n",
    "            next_state = learner.get_next_state()\n",
    "            \n",
    "            learner.move(next_state, learned_reward_table[learner.state][learner.action])\n",
    "            \n",
    "            learner.num_iteration += 1 \n",
    "        \n",
    "            if learner.num_iteration % learner.scaling_point == 0: \n",
    "                learner.qtable *= learner.scaling_factor\n",
    "            \n",
    "            \n",
    "#             for s in xrange(0, learner.num_states):\n",
    "#                 for a in xrange (0, learner.num_actions):\n",
    "#                     if s != learner.state or a != learner.action:\n",
    "                        \n",
    "#                         next_state_temp = get_next_state_temp(learner, s, a)\n",
    "                        \n",
    "#                         temp_r = learned_reward_table[s][a] - learner.action_penalty\n",
    "                        \n",
    "#                         choose_random_action = (1 - learner.random_action_rate) <= np.random.uniform(0, 1)\n",
    "\n",
    "#                         if choose_random_action:\n",
    "#                             action_prime_temp = np.random.randint(0, learner.num_actions)\n",
    "#                         else:\n",
    "#                             action_prime_temp = learner.qtable[next_state_temp].argsort()[-1]\n",
    "\n",
    "\n",
    "#                         learner.qtable[s, a] += learner.alpha * (temp_r + learner.gamma * learner.qtable[next_state_temp, action_prime_temp] - learner.qtable[s, a])\n",
    "                    \n",
    "            \n",
    "    \n",
    "        reward_vector.append(np.mean(temp_reward))\n",
    "    \n",
    "            \n",
    "        \n",
    "    normalize_state_vector = (state_vector/np.sum(state_vector)) * 100.\n",
    "    state_map = pd.DataFrame(normalize_state_vector.reshape(learner.servo_num_states, -1))\n",
    "    sns.heatmap(state_map, linewidths=1, annot=True)\n",
    "    plt.title('State map after {} simulations in %'.format(num_simulation))\n",
    "    \n",
    "    normalize_action_vector = (action_vector/np.sum(action_vector)) * 100.\n",
    "    \n",
    "    #print len(reward_vector)\n",
    "    print \"\\nReward per action: \",np.mean(reward_vector)\n",
    "    #print normalize_action_vector\n",
    "    \n",
    "    return learner, learned_reward_table\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_params = {'warm_up_period': 44.0, \n",
    "               'scaling_factor': 1.0372293641209551, \n",
    "               'random_action_decay_rate': 0.5900692779721906, \n",
    "               'random_action_rate': 0.18634870253656852, \n",
    "               'alpha': 0.9764032895801622, \n",
    "               'scaling_point': 16, \n",
    "               'gamma': 0.964381829500279}\n",
    "\n",
    "best_params = {'warm_up_period': 38.0, \n",
    "               'scaling_factor': 1.1130568801499376, \n",
    "               'random_action_decay_rate': 0.9505348646463121, \n",
    "               'random_action_rate': 0.19293344201527163, \n",
    "               'alpha': 0.7680484211161775, \n",
    "               'scaling_point': 300,\n",
    "               'gamma': 0.9527683563414476}\n",
    "\n",
    "best_params = {'warm_up_period': 38.0, \n",
    "               'scaling_factor': 1.1130568801499376, \n",
    "               'random_action_decay_rate': 0.9505348646463121, \n",
    "               'random_action_rate': 0.19293344201527163, \n",
    "               'alpha': 0.7680484211161775, \n",
    "               'scaling_point': 300, \n",
    "               'gamma': 0.9527683563414476}\n",
    "\n",
    "best_params = {'warm_up_period': 15.0, \n",
    "               'scaling_factor': 1.1669767007065206, \n",
    "               'random_action_decay_rate': 0.283102086404449, \n",
    "               'random_action_rate': 0.3881361927595925, \n",
    "               'alpha': 0.7480711423078713, \n",
    "               'scaling_point': 155, \n",
    "               'gamma': 0.9846208655721159}\n",
    "\n",
    "best_params = {'warm_up_period': 96.0, \n",
    "               'scaling_factor': 1.6944560688012607, \n",
    "               'random_action_decay_rate': 0.545267375797949, \n",
    "               'random_action_rate': 0.10056735562002306, \n",
    "               'alpha': 0.6227095466939823, \n",
    "               'scaling_point': 190, \n",
    "               'gamma': 0.932459803334474}\n",
    "\n",
    "best_params =  {'warm_up_period': 14.0, 'scaling_factor': 1.1129161749445728, 'random_action_decay_rate': 0.6320229427611553, 'random_action_rate': 0.955872080367004, 'alpha': 0.6029734543946844, 'scaling_point': 30, 'gamma': 0.9565818726183515}\n",
    "\n",
    "learner, learned_reward_table = crawling_simulation(best_params, reward_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-792., -784., -776., -768., -760., -752., -744., -736., -728.,\n",
       "       -720., -712., -704., -696., -688., -680., -672., -664., -656.,\n",
       "       -648., -640., -632., -624., -616., -608., -600., -592., -584.,\n",
       "       -576., -568., -560., -552., -544., -536., -528., -520., -512.,\n",
       "       -504., -496., -488., -480., -472., -464., -456., -448., -440.,\n",
       "       -432., -424., -416., -408., -400., -392., -384., -376., -368.,\n",
       "       -360., -352., -344., -336., -328., -320., -312., -304., -296.,\n",
       "       -288., -280., -272., -264., -256., -248., -240., -232., -224.,\n",
       "       -216., -208., -200., -192., -184., -176., -168., -160., -152.,\n",
       "       -144., -136., -128., -120., -112., -104.,  -96.,  -88.,  -80.,\n",
       "        -72.,  -64.,  -56.,  -48.,  -40.,  -32.,  -24.,  -16.,   -8.,\n",
       "          0.,    8.,   16.,   24.,   32.,   40.,   48.,   56.,   64.,\n",
       "         72.,   80.,   88.,   96.,  104.,  112.,  120.,  128.,  136.,\n",
       "        144.,  152.,  160.,  168.,  176.,  184.,  192.,  200.,  208.,\n",
       "        216.,  224.,  232.,  240.,  248.,  256.,  264.,  272.,  280.,\n",
       "        288.,  296.,  304.,  312.,  320.,  328.,  336.,  344.,  352.,\n",
       "        360.,  368.,  376.,  384.,  392.,  400.,  408.,  416.,  424.,\n",
       "        432.,  440.,  448.,  456.,  464.,  472.,  480.,  488.,  496.,\n",
       "        504.,  512.,  520.,  528.,  536.,  544.,  552.,  560.,  568.,\n",
       "        576.,  584.,  592.,  600.,  608.,  616.,  624.,  632.,  640.,\n",
       "        648.,  656.,  664.,  672.,  680.,  688.,  696.,  704.,  712.,\n",
       "        720.,  728.,  736.,  744.,  752.,  760.,  768.,  776.,  784.,  792.])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_bins = pd.cut([-800, 800], bins=200, retbins=True)[1][1:-1]\n",
    "\n",
    "reward_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_bin(150, reward_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "\n",
      "Reward per action:  -0.0008675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAHsCAYAAAAEiX1wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1199462d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def crawling_simulation(params, reward_table, training_iteration = 50000, num_simulation = 1):\n",
    "    \n",
    "    state_vector = np.zeros(49)\n",
    "    action_vector = np.zeros(4)\n",
    "    reward_vector = []\n",
    "    \n",
    "    for simulation in tqdm(xrange(num_simulation)):\n",
    "        \n",
    "        temp_reward = []\n",
    "\n",
    "        learner = QLearner(servo_num_states = 7,\n",
    "                   num_actions=4,\n",
    "                   alpha=float(params['alpha']),\n",
    "                   gamma=float(params['gamma']),\n",
    "                   random_action_rate=float(params['random_action_rate']),\n",
    "                   random_action_decay_rate=float(params['random_action_decay_rate']),\n",
    "                   warm_up_period=int(params['warm_up_period']),\n",
    "                   action_penalty=50,\n",
    "                   negative_reward_coef=1.,#float(params['negative_reward_coef']),\n",
    "                   interest_zone_reward_coef = 1, #1.32, #float(params['interest_zone_reward_coef']),\n",
    "                   initial_state=24,\n",
    "                   scaling_point = params['scaling_point'],\n",
    "                   scaling_factor = params['scaling_factor'])#int(params['initial_state'])) #float(params['action_penalty']))\n",
    "\n",
    "        \n",
    "        num_exploration_step = 50000\n",
    "        \n",
    "        learned_reward_table = np.zeros((learner.num_states, learner.num_actions))\n",
    "    \n",
    "        for iteration_step in xrange(training_iteration):\n",
    "            \n",
    "            state_vector[learner.state] += 1\n",
    "            action_vector[learner.action] += 1 \n",
    "    \n",
    "            if iteration_step > training_iteration-30 and simulation == num_simulation-1:\n",
    "                print learner.state \n",
    "            \n",
    "            if iteration_step < num_exploration_step:\n",
    "            \n",
    "                ideal_reward = reward_table[learner.state][learner.action] \n",
    "                random_noise = np.random.normal(0, np.abs(ideal_reward)*.25) if ideal_reward != 0 else 0 \n",
    "                noisy_reward = ideal_reward + random_noise - learner.action_penalty\n",
    "\n",
    "                if learner.state % learner.servo_num_states > 2 and learner.state < 30:\n",
    "                    reward = noisy_reward * learner.interest_zone_reward_coef if noisy_reward > 0 else noisy_reward * learner.negative_reward_coef\n",
    "                else:\n",
    "                    reward = noisy_reward\n",
    "\n",
    "                if noisy_reward > 0:\n",
    "                    noisy_reward = 1\n",
    "                elif noisy_reward < 0:\n",
    "                    noisy_reward = -1 \n",
    "                    \n",
    "#                 if learned_reward_table[learner.state][learner.action] != 0:\n",
    "#                     learned_reward_table[learner.state][learner.action] = .5*(learned_reward_table[learner.state][learner.action] + noisy_reward)\n",
    "#                 else:\n",
    "#                     learned_reward_table[learner.state][learner.action] = noisy_reward\n",
    "\n",
    "\n",
    "                learned_reward_table[learner.state][learner.action] = .5*(learned_reward_table[learner.state][learner.action] + noisy_reward)\n",
    "\n",
    "\n",
    "                temp_reward.append(learned_reward_table[learner.state][learner.action])\n",
    "\n",
    "                next_state = learner.get_next_state()\n",
    "\n",
    "                learner.move(next_state, learned_reward_table[learner.state][learner.action])\n",
    "\n",
    "                learner.num_iteration += 1 \n",
    "\n",
    "                if learner.num_iteration % learner.scaling_point == 0: \n",
    "                    learner.qtable *= learner.scaling_factor\n",
    "\n",
    "            else:\n",
    "                \n",
    "                reward = learned_reward_table[learner.state][learner.action]\n",
    "                temp_reward.append(learned_reward_table[learner.state][learner.action])\n",
    "\n",
    "                if noisy_reward >= 0:\n",
    "                    noisy_reward = 1\n",
    "                else: \n",
    "                    noisy_reward = -1 \n",
    "                \n",
    "                next_state = learner.get_next_state()\n",
    "                learner.move(next_state, learned_reward_table[learner.state][learner.action])\n",
    "                learner.num_iteration += 1 \n",
    "\n",
    "                if learner.num_iteration % learner.scaling_point == 0: \n",
    "                    learner.qtable *= learner.scaling_factor\n",
    "                \n",
    "                    \n",
    "        reward_vector.append(np.mean(temp_reward))\n",
    "    \n",
    "            \n",
    "        \n",
    "    normalize_state_vector = (state_vector/np.sum(state_vector)) * 100.\n",
    "    state_map = pd.DataFrame(normalize_state_vector.reshape(learner.servo_num_states, -1))\n",
    "    sns.heatmap(state_map, linewidths=1, annot=True)\n",
    "    plt.title('State map after {} simulations in %'.format(num_simulation))\n",
    "    \n",
    "    normalize_action_vector = (action_vector/np.sum(action_vector)) * 100.\n",
    "    \n",
    "    #print len(reward_vector)\n",
    "    print \"\\nReward per action: \",np.mean(reward_vector)\n",
    "    #print normalize_action_vector\n",
    "    \n",
    "    return learner, learned_reward_table\n",
    "\n",
    "\n",
    "\n",
    "best_params = {'warm_up_period': 96.0, \n",
    "               'scaling_factor': 1.6944560688012607, \n",
    "               'random_action_decay_rate': 0.545267375797949, \n",
    "               'random_action_rate': 0.10056735562002306, \n",
    "               'alpha': 0.6227095466939823, \n",
    "               'scaling_point': 190, \n",
    "               'gamma': 0.932459803334474}\n",
    "\n",
    "best_params =   {'warm_up_period': 90.0, \n",
    "                 'scaling_factor': 3.6044006257743333, \n",
    "                 'random_action_decay_rate': 0.824709435216204, \n",
    "                 'random_action_rate': 0.834614308862227, \n",
    "                 'alpha': 0.3092353715331193, \n",
    "                 'scaling_point': 275, \n",
    "                 'gamma': 0.37419656297319936}\n",
    "\n",
    "best_params =  {'warm_up_period': 14.0, 'scaling_factor': 1.1129161749445728, 'random_action_decay_rate': 0.6320229427611553, 'random_action_rate': 0.955872080367004, 'alpha': 0.6029734543946844, 'scaling_point': 30, 'gamma': 0.9565818726183515}\n",
    "\n",
    "\n",
    "learner, learned_reward_table = crawling_simulation(best_params, reward_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.  , -0.75, -0.75, -0.75],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.75],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [-0.5 ,  1.  , -0.5 , -0.75],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.75],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.5 , -0.5 , -0.75],\n",
       "       [-0.75,  0.5 , -0.5 , -0.5 ],\n",
       "       [-0.5 ,  0.  ,  0.  ,  0.5 ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.5 ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learned_reward_table[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-250, -15000, -405, -15000]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_table[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1463.8918091224812"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(learned_reward_table[0] - reward_table[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   79.81510783   702.65369531    81.77455242  4991.32388093]\n",
      "[   56.99132307  2516.69572685    69.13761699    91.69393902]\n",
      "[   73.60074697  3001.40237076    52.92744526    82.21528799]\n",
      "[   231.          15000.             77.             64.74299803]\n",
      "[    61.  15000.      0.     77.]\n",
      "[     0.  15000.      0.      0.]\n",
      "[     0.  15000.  15000.      0.]\n",
      "[  149.10894403    43.5815364      4.25129222  2097.36118516]\n",
      "[  63.95155894   87.03765296  170.47768212  102.63808143]\n",
      "[ 200.            3.53525224   64.71355204   85.94717312]\n",
      "[  90.37762556  231.           10.           44.14309636]\n",
      "[  2.  61.   0.  10.]\n",
      "[ 0.  0.  0.  0.]\n",
      "[     0.      0.  15000.      0.]\n",
      "[   66.44445243   135.58474784    45.79202003  4278.3198053 ]\n"
     ]
    }
   ],
   "source": [
    "x = 3\n",
    "for x in xrange(15):\n",
    "    print np.abs(learned_reward_table[x] - reward_table[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
