{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "import time\n",
    "import datetime \n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import collections\n",
    "import unicodedata\n",
    "import collections\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from datetime import datetime, date, timedelta\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = 10,8\n",
    "\n",
    "plt.style.use('bmh')\n",
    "colors = ['#348ABD', '#A60628', '#7A68A6', '#467821', '#D55E00', \n",
    "          '#CC79A7', '#56B4E9', '#009E73', '#F0E442', '#0072B2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reward_table = [\n",
    "    [ -250 , -15000, -405 , -15000],\n",
    "    [-309 , -15000, -400 , 405  ],\n",
    "    [-262 , -15000, -255 , 400  ],\n",
    "    [-231 , -15000, -77  , 255  ],\n",
    "    [-61  , -15000, 0    , 77   ],\n",
    "    [0    , -15000, 0    , 0    ],\n",
    "    [0    , -15000, -15000, 0    ],\n",
    "    [-325 , 250  , -452 , -15000],\n",
    "    [-270 , 309  , -325 , 452  ],\n",
    "    [-200 , 262  , -190 , 325  ],\n",
    "    [-125 , 231  , -10  , 190  ],\n",
    "    [-2   , 61   , 0    , 10   ],\n",
    "    [0    , 0    , 0    , 0    ],\n",
    "    [0    , 0    , -15000, 0    ],\n",
    "    [-192 , 325  , -390 , -15000],\n",
    "    [-169 , 270  , -285 , -390 ],\n",
    "    [-105 , 200  , -132 , 285  ],\n",
    "    [-10  , 125  , -5   , 132  ],\n",
    "    [0    , 2    , 0    , 5    ],\n",
    "    [0    , 0    , 0    , 0    ],\n",
    "    [0    , 0    , -15000, 0    ],\n",
    "    [-117 , 192  , -350 , -15000],\n",
    "    [-67  , 169  , -235 , 350  ],\n",
    "    [-8   , 105  , -26  , 235  ],\n",
    "    [0    , 10   , 0    , 26   ],\n",
    "    [0    , 0    , 0    , 0    ],\n",
    "    [0    , 0    , 0    , 0    ],\n",
    "    [0    , 0    , -15000, 0    ],\n",
    "    [-38  , 117  , -250 , -15000],\n",
    "    [0    , 67   , -148 , 250  ],\n",
    "    [0    , 8    , -3   , 148  ],\n",
    "    [0    , 0    , 0    , 3    ],\n",
    "    [0    , 0    , 0    , 0    ],\n",
    "    [0    , 0    , 0    , 0    ],\n",
    "    [0    , 0    , -15000, 0    ],\n",
    "    [0    , 38   , -195 , -15000],\n",
    "    [0    , 0    , -193 , 195  ],\n",
    "    [0    , 0    , -5   , 193  ],\n",
    "    [0    , 0    , 0    , 5    ],\n",
    "    [0    , 0    , 0    , 0    ],\n",
    "    [0    , 0    , 0    , 0    ],\n",
    "    [0    , 0    , -15000, 0    ],\n",
    "    [-15000, 0    , -255 , -15000],\n",
    "    [-15000, 0    , -190 , 255  ],\n",
    "    [-15000, 0    , -8   , 190  ],\n",
    "    [-15000, 0    , 0    , 8   ],\n",
    "    [-15000, 0    , 0    , 0    ],\n",
    "    [-15000, 0    , 0    , 0    ],\n",
    "    [-15000, 0    , -15000, 0    ]\n",
    "]; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def softmax(f):\n",
    "    f = f - np.max(f)\n",
    "    p = np.exp(f) / np.sum(np.exp(f))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "softmax_reward_table = np.apply_along_axis(softmax, 1, reward_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def action_is_allowed(learner, state, action):\n",
    "\n",
    "    if (action == 0 and not(state > learner.num_states - learner.servo_num_states - 1)):\n",
    "        return True\n",
    "    elif (action == 1 and not(state < learner.servo_num_states)):\n",
    "        return True\n",
    "    elif (action == 2 and not((state%learner.servo_num_states) == (learner.servo_num_states-1))):\n",
    "        return True\n",
    "    elif (action == 3 and not(state%learner.servo_num_states==0)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class QLearner(object):\n",
    "    def __init__(self, \n",
    "                 servo_num_states, \n",
    "                 num_actions, \n",
    "                 alpha, \n",
    "                 gamma, \n",
    "                 random_action_rate,\n",
    "                 random_action_decay_rate, \n",
    "                 warm_up_period, \n",
    "                 action_penalty,\n",
    "                 negative_reward_coef,\n",
    "                 interest_zone_reward_coef,\n",
    "                 initial_state):\n",
    "        \n",
    "        self.servo_num_states = servo_num_states\n",
    "        self.num_states = servo_num_states**2\n",
    "        self.num_actions = num_actions\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.random_action_rate = random_action_rate\n",
    "        self.random_action_decay_rate = random_action_decay_rate\n",
    "        self.warm_up_period = warm_up_period\n",
    "        self.state = initial_state\n",
    "        self.action = 0\n",
    "        self.action_penalty = action_penalty\n",
    "        #self.qtable = np.random.uniform(low=-1, high=1, size=(self.num_states, self.num_actions))\n",
    "        self.qtable = np.zeros((self.num_states, self.num_actions))\n",
    "        self.num_iteration = 0\n",
    "        self.last_reward = 0\n",
    "        self.negative_reward_coef = negative_reward_coef\n",
    "        self.interest_zone_reward_coef = interest_zone_reward_coef\n",
    "        self.scaling_factor = 1\n",
    "        \n",
    "    def set_initial_state(self, action):\n",
    "        \"\"\"\n",
    "        @summary: Sets the initial state and returns an action\n",
    "        @param state: The initial state\n",
    "        @returns: The selected action\n",
    "        \"\"\"\n",
    "        self.state = int(self.num_states/2)\n",
    "        self.action = action #self.qtable[state].argsort()[-1]\n",
    "        \n",
    "    def get_next_state(self):\n",
    "        \n",
    "        next_state = None\n",
    "        \n",
    "        if (self.action == 0 and action_is_allowed(self, self.state, self.action)): \n",
    "            next_state = self.state + self.servo_num_states\n",
    "        elif (self.action == 1 and action_is_allowed(self, self.state, self.action)):\n",
    "            next_state = self.state - self.servo_num_states\n",
    "        elif (self.action == 2 and action_is_allowed(self, self.state, self.action)):\n",
    "            next_state = self.state + 1\n",
    "        elif (self.action == 3 and action_is_allowed(self, self.state, self.action)):\n",
    "            next_state = self.state - 1 \n",
    "        else:\n",
    "            next_state = self.state;\n",
    "            \n",
    "        return next_state\n",
    "        \n",
    "    def move(self, state_prime, reward):\n",
    "        \"\"\"\n",
    "        @summary: Moves to the given state with given reward and returns action\n",
    "        @param state_prime: The new state\n",
    "        @param reward: The reward\n",
    "        @returns: The selected action\n",
    "        \"\"\"\n",
    "        alpha = self.alpha\n",
    "        gamma = self.gamma\n",
    "        state = self.state\n",
    "        action = self.action\n",
    "        qtable = self.qtable\n",
    "        action_prime = -1\n",
    "        \n",
    "#         if self.state == state_prime: \n",
    "\n",
    "#             while not self.action_is_allowed(action_prime):\n",
    "#                 action_prime = np.random.randint(0, self.num_actions)\n",
    "            \n",
    "#             self.action = action_prime\n",
    "            \n",
    "        if False:\n",
    "            print 'yo'\n",
    "            \n",
    "        else: \n",
    "            \n",
    "            choose_random_action = (1 - self.random_action_rate) <= np.random.uniform(0, 1)\n",
    "\n",
    "            if choose_random_action:\n",
    "#                 while not(action_is_allowed(self, state_prime, action_prime)): \n",
    "                action_prime = np.random.randint(0, self.num_actions)\n",
    "            else:\n",
    "                ordered_action_list = self.qtable[state_prime].argsort()\n",
    "                best_choice_index = -1\n",
    "#                 while not(action_is_allowed(self, state_prime, action_prime)):\n",
    "                action_prime = ordered_action_list[best_choice_index]\n",
    "#                     best_choice_index -= 1\n",
    "\n",
    "            if self.num_iteration > self.warm_up_period: # warm up period is over\n",
    "                self.random_action_rate *= self.random_action_decay_rate\n",
    "                    \n",
    "            \n",
    "            if reward < 0 and np.abs(reward) < 15000:\n",
    "                reward = reward * self.negative_reward_coef\n",
    "            \n",
    "            if self.num_iteration % 50 == 0:\n",
    "                qtable *= self.scaling_factor\n",
    "                \n",
    "            \n",
    "            qtable[state, action] = qtable[state, action] + alpha * (reward + gamma * qtable[state_prime, action_prime] - qtable[state, action])\n",
    "\n",
    "            self.state = state_prime\n",
    "            self.action = action_prime    \n",
    "            self.qtable = qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_final_reward(learner, reward_table, training_iteration):\n",
    "    \n",
    "    reward_list = []\n",
    "    \n",
    "    for iteration_step in xrange(training_iteration):\n",
    "\n",
    "        reward = reward_table[learner.state][learner.action] - learner.action_penalty\n",
    "\n",
    "        if learner.state % learner.servo_num_states > 2 and learner.state < 30:\n",
    "            reward = reward * learner.interest_zone_reward_coef if reward > 0 else reward\n",
    "            \n",
    "        if reward < 0:\n",
    "            reward *= learner.negative_reward_coef\n",
    "        \n",
    "        next_state = learner.get_next_state()\n",
    "\n",
    "        learner.move(next_state, reward)\n",
    "        \n",
    "        learner.num_iteration += 1 \n",
    "\n",
    "        reward_list.append(np.mean(reward))\n",
    "        \n",
    "    return np.mean(reward_list)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, hp, STATUS_OK, Trials\n",
    "import datetime\n",
    "\n",
    "best_score = np.inf\n",
    "\n",
    "def score(params):\n",
    "    \n",
    "    global best_score    \n",
    "    \n",
    "    num_iteration = 2\n",
    "    \n",
    "    loss_vector = []\n",
    "    \n",
    "    for i in xrange(num_iteration):\n",
    "    \n",
    "        learner = QLearner(servo_num_states = 7,\n",
    "                           num_actions=4,\n",
    "                           alpha=float(params['alpha']),\n",
    "                           gamma=float(params['gamma']),\n",
    "                           random_action_rate=float(params['random_action_rate']),\n",
    "                           random_action_decay_rate=float(params['random_action_decay_rate']),\n",
    "                           warm_up_period=int(params['warm_up_period']),\n",
    "                           action_penalty=50,\n",
    "                           negative_reward_coef=1, #float(params['negative_reward_coef']),\n",
    "                           interest_zone_reward_coef =1, #float(params['interest_zone_reward_coef']),\n",
    "                           initial_state=24)#int(params['initial_state'])) #float(params['action_penalty']))\n",
    "        #learner.set_initial_state(action=0)\n",
    "\n",
    "        temp_loss = - get_final_reward(learner, reward_table, training_iteration=50000) # negative because we want to minimize loss\n",
    "        loss_vector.append(temp_loss)\n",
    "        \n",
    "    loss = np.mean(loss_vector)\n",
    "    \n",
    "    if loss < best_score: \n",
    "        print \"Searching...\", \n",
    "        print \"New best score: {0:.6f}\".format(-loss), \n",
    "        print params \n",
    "        print datetime.datetime.now().time()\n",
    "        print\n",
    "        best_score = loss\n",
    "\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "    \n",
    "def optimize(trials):\n",
    "        \n",
    "    space = {\n",
    "             'alpha': hp.uniform('alpha', 0.1, 1),\n",
    "             'gamma': hp.uniform('gamma', 0.1, 1),\n",
    "             'random_action_rate': hp.uniform('random_action_rate', 0.1,1), \n",
    "             'random_action_decay_rate': hp.uniform('random_action_decay_rate', 0.1, 1),\n",
    "             'warm_up_period': hp.quniform('warm_up_period', 0, 50, 1)\n",
    "#              'initial_state': hp.quniform('initial_state', 0, 47, 1)\n",
    "#              'negative_reward_coef': hp.uniform('negative_reward_coef', 1, 1.5),\n",
    "#              'interest_zone_reward_coef': hp.uniform('interest_zone_reward_coef', 1, 1.5)\n",
    "            }\n",
    "\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=500)\n",
    "\n",
    "    print '------------------------' \n",
    "    print \"Done.\"\n",
    "    print \"Best parameter setting:\", best\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching... New best score: -54.033230 {'random_action_rate': 0.5932182468439383, 'warm_up_period': 18.0, 'gamma': 0.9076247919054737, 'random_action_decay_rate': 0.9627554365415967, 'alpha': 0.27031053808280464}\n",
      "17:24:04.566655\n",
      "\n",
      "Searching... New best score: -53.742400 {'random_action_rate': 0.2942254782758122, 'warm_up_period': 31.0, 'gamma': 0.19769316709691204, 'random_action_decay_rate': 0.7866836786669388, 'alpha': 0.2647812653804158}\n",
      "17:24:11.853936\n",
      "\n",
      "Searching... New best score: -52.542280 {'random_action_rate': 0.7009944029877727, 'warm_up_period': 17.0, 'gamma': 0.7280447375987511, 'random_action_decay_rate': 0.6288218749572573, 'alpha': 0.5732708531604611}\n",
      "17:24:22.759437\n",
      "\n",
      "Searching... New best score: -51.488520 {'random_action_rate': 0.6971195639784412, 'warm_up_period': 35.0, 'gamma': 0.4922456690325856, 'random_action_decay_rate': 0.884151244614023, 'alpha': 0.42342305392704693}\n",
      "17:24:26.350238\n",
      "\n",
      "Searching... New best score: -36.359900 {'random_action_rate': 0.9943732853137817, 'warm_up_period': 34.0, 'gamma': 0.9848296961148684, 'random_action_decay_rate': 0.5513347280847156, 'alpha': 0.426402234221428}\n",
      "17:25:42.724750\n",
      "\n",
      "Searching... New best score: -32.839660 {'random_action_rate': 0.3019595582543259, 'warm_up_period': 46.0, 'gamma': 0.9758541654964458, 'random_action_decay_rate': 0.4885980315144308, 'alpha': 0.7155591636155634}\n",
      "17:26:24.768307\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-223-a5c8481f0eb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'\\n#Trials object where the history of search will be stored\\ntrials = Trials()\\n\\nbest_params = optimize(trials)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/admin/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2120\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/admin/anaconda/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/anaconda/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-222-e3d98794101e>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(trials)\u001b[0m\n\u001b[1;32m     55\u001b[0m             }\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'------------------------'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/anaconda/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/anaconda/lib/python2.7/site-packages/hyperopt/base.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return_argmin=return_argmin)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/anaconda/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     verbose=verbose)\n\u001b[1;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/anaconda/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/anaconda/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/anaconda/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/anaconda/lib/python2.7/site-packages/hyperopt/base.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-222-e3d98794101e>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#learner.set_initial_state(action=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtemp_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mget_final_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# negative because we want to minimize loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mloss_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-148-65a9ffa05169>\u001b[0m in \u001b[0;36mget_final_reward\u001b[0;34m(learner, reward_table, training_iteration)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_iteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mreward_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/anaconda/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   2940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 2942\u001b[0;31m                             out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/anaconda/lib/python2.7/site-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Trials object where the history of search will be stored\n",
    "trials = Trials()\n",
    "\n",
    "best_params = optimize(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400.0"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1600*.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.666666666666667"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "400/60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 10.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "11\n",
      "18\n",
      "17\n",
      "10\n",
      "3\n",
      "4\n",
      "11\n",
      "18\n",
      "17\n",
      "10\n",
      "3\n",
      "4\n",
      "11\n",
      "18\n",
      "17\n",
      "10\n",
      "3\n",
      "4\n",
      "11\n",
      "18\n",
      "17\n",
      "10\n",
      "3\n",
      "4\n",
      "11\n",
      "18\n",
      "17\n",
      "\n",
      "Reward per action:  -176.51034606\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAHsCAYAAAAEiX1wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/h+ZSqeYouNT6gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ac0f7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def crawling_simulation(params, reward_table, training_iteration = 5000, num_simulation = 2):\n",
    "    \n",
    "    state_vector = np.zeros(49)\n",
    "    action_vector = np.zeros(4)\n",
    "    reward_vector = []\n",
    "    \n",
    "    for simulation in tqdm(xrange(num_simulation)):\n",
    "        \n",
    "        temp_reward = []\n",
    "        \n",
    "#         learner = QLearner(servo_num_states = 7,\n",
    "#                            num_actions=4,\n",
    "#                            alpha=float(params['alpha']),\n",
    "#                            gamma=float(params['gamma']),\n",
    "#                            random_action_rate=float(params['random_action_rate']),\n",
    "#                            random_action_decay_rate=float(params['random_action_decay_rate']),\n",
    "#                            warm_up_period=int(params['warm_up_period']),\n",
    "#                            action_penalty=50,\n",
    "#                            negative_reward_coef= flaot,\n",
    "#                            interest_zone_reward_coef = 1.1,\n",
    "#                            initial_state=int(params['initial_state'])) #float(params['action_penalty']))\n",
    "        \n",
    "        learner = QLearner(servo_num_states = 7,\n",
    "                   num_actions=4,\n",
    "                   alpha=float(params['alpha']),\n",
    "                   gamma=float(params['gamma']),\n",
    "                   random_action_rate=float(params['random_action_rate']),\n",
    "                   random_action_decay_rate=float(params['random_action_decay_rate']),\n",
    "                   warm_up_period=int(params['warm_up_period']),\n",
    "                   action_penalty=50,\n",
    "                   negative_reward_coef=1.,#float(params['negative_reward_coef']),\n",
    "                   interest_zone_reward_coef = 1.32, #float(params['interest_zone_reward_coef']),\n",
    "                   initial_state=24)#int(params['initial_state'])) #float(params['action_penalty']))\n",
    "\n",
    "#         learner.set_initial_state(action=0)\n",
    "\n",
    "        stop = False\n",
    "    \n",
    "        for iteration_step in xrange(training_iteration):\n",
    "            \n",
    "#             if learner.num_iteration == 1000:\n",
    "#                 print learner.qtable[0]\n",
    "\n",
    "            \n",
    "            state_vector[learner.state] += 1\n",
    "            action_vector[learner.action] += 1 \n",
    "            \n",
    "#             if iteration_step - 1 == learner.warm_up_period and simulation == 0:\n",
    "#                 #print learner.state, learner.action, learner.qtable[learner.state]\n",
    "#                 print learner.qtable\n",
    "                \n",
    "#             if iteration_step == 9980  and simulation == 0:\n",
    "#                 #print learner.state, learner.action, learner.qtable[learner.state]\n",
    "#                 print learner.qtable\n",
    "                \n",
    "#             if iteration_step > 3000 and iteration_step < 3020:\n",
    "#                 print learner.state\n",
    "    \n",
    "            if iteration_step > training_iteration-30 and simulation == num_simulation-1:\n",
    "                print learner.state \n",
    "#                 print learner.qtable\n",
    " \n",
    "                            \n",
    "\n",
    "                \n",
    "            reward = reward_table[learner.state][learner.action]*np.random.uniform(.5,1.5) - learner.action_penalty\n",
    "            \n",
    "            if learner.state % learner.servo_num_states > 2 and learner.state < 30:\n",
    "                reward = reward * learner.interest_zone_reward_coef if reward > 0 else reward * learner.negative_reward_coef\n",
    "            \n",
    "#             if reward < 0:\n",
    "#                 reward *= learner.negative_reward_coef\n",
    "            \n",
    "            temp_reward.append(reward)\n",
    "            \n",
    "            next_state = learner.get_next_state()\n",
    "            \n",
    "#             dup = False\n",
    "#             if next_state == learner.state:\n",
    "#                 dup = True\n",
    "#                 print iteration_step, next_state, learner.action, reward, \n",
    "\n",
    "            learner.move(next_state, reward)\n",
    "            learner.num_iteration += 1 \n",
    "#             if dup:\n",
    "#                 print next_state\n",
    "#                 print learner.qtable[next_state]\n",
    "#                 print '----'\n",
    "        reward_vector.append(np.mean(temp_reward))\n",
    "        \n",
    "    normalize_state_vector = (state_vector/np.sum(state_vector)) * 100.\n",
    "    state_map = pd.DataFrame(normalize_state_vector.reshape(learner.servo_num_states, -1))\n",
    "    sns.heatmap(state_map, linewidths=1, annot=True)\n",
    "    plt.title('State map after {} simulations in %'.format(num_simulation))\n",
    "    \n",
    "    normalize_action_vector = (action_vector/np.sum(action_vector)) * 100.\n",
    "    \n",
    "    #print len(reward_vector)\n",
    "    print \"\\nReward per action: \",np.mean(reward_vector)\n",
    "    #print normalize_action_vector\n",
    "    \n",
    "    return learner\n",
    "\n",
    "\n",
    "# best_params = {'alpha': 0.40619963352672517, \n",
    "#                'random_action_decay_rate': 0.8189717113594237, \n",
    "#                'gamma': 0.9760578814233064, \n",
    "#                'warm_up_period': 341.0}\n",
    "# best_params = {'warm_up_period': 363.0, \n",
    "#                'negative_reward_coef': 1.657585408801534, \n",
    "#                'gamma': 0.9744212450698116, \n",
    "#                'random_action_decay_rate': 0.7206861521993938, \n",
    "#                'alpha': 0.7199800066939188}\n",
    "# best_params = {'alpha': 0.9613645426995369, \n",
    "#                'random_action_decay_rate': 0.6862739427670339, \n",
    "#                'gamma': 0.9680926035857673, \n",
    "#                'warm_up_period': 65.0}\n",
    "\n",
    "\n",
    "# best_params = {'warm_up_period': 5.0, \n",
    "#                'random_action_decay_rate': 0.5541460471345169, \n",
    "#                'alpha': 0.7506149332042706, \n",
    "#                'initial_state': 12.0, \n",
    "#                'random_action_rate': 0.8708637956794232, \n",
    "#                'gamma': 0.9791556652375034} \n",
    "\n",
    "\n",
    "best_params = {'random_action_rate': 0.3019595582543259, 'warm_up_period': 46.0, 'gamma': 0.9758541654964458, 'random_action_decay_rate': 0.4885980315144308, 'alpha': 0.7155591636155634}\n",
    "learner = crawling_simulation(best_params, reward_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8384998419585881"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(.7,1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
